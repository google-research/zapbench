{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjGO3YwWLzbx"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "This tutorial describes how to access datasets associated with ZAPBench with Python.\n",
        "\n",
        "Datasets are hosted on Google Cloud Storage in the `zapbench-release` bucket, see [dataset README for acknowledgements and license (CC-BY)](http://zapbench-release.storage.googleapis.com/volumes/README.html). Datasets that may be especially relevant include:\n",
        "\n",
        "- Functional activity volume (`gs://zapbench-release/volumes/20240930/raw`)\n",
        "- Functional anatomy volume (`gs://zapbench-release/volumes/20240930/anatomy`)\n",
        "- Aligned activity volume (`gs://zapbench-release/volumes/20240930/aligned`)\n",
        "- Aligned and normalized activity volume (`gs://zapbench-release/volumes/20240930/df_over_f`)\n",
        "- Annotations used for segmentation model training and eval (`gs://zapbench-release/volumes/20240930/annotations/...`)\n",
        "- Segmentation used to extract traces (`gs://zapbench-release/volumes/20240930/segmentation`)\n",
        "- Traces used for time-series forecasting (`gs://zapbench-release/volumes/20240930/traces`)\n",
        "\n",
        "Datasets can also be browsed and downloaded directly using [gsutil](https://cloud.google.com/storage/docs/gsutil), e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-O1e6d4ZUQQM"
      },
      "outputs": [],
      "source": [
        "!gsutil ls gs://zapbench-release/volumes/20240930/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwCUStaNfYcr"
      },
      "source": [
        "## Loading datasets with TensorStore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W6CUOmcfbbj"
      },
      "source": [
        "We can access these datasets using using [TensorStore](https://google.github.io/tensorstore/). Let's load the raw activity volume, for example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJwFKHwqd7Rd"
      },
      "outputs": [],
      "source": [
        "!pip install tensorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiM8zpVCNRuR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorstore as ts\n",
        "\n",
        "\n",
        "# Create handle to the remote dataset.\n",
        "ds = ts.open({\n",
        "    'open': True,\n",
        "    # Datasets are generally stored in zarr v3 format ('zarr3').\n",
        "    # There are a few exceptions, where v2 is used ('zarr').\n",
        "    'driver': 'zarr3',\n",
        "    # Path of the dataset we want to load.\n",
        "    'kvstore': 'gs://zapbench-release/volumes/20240930/raw'\n",
        "}).result()\n",
        "\n",
        "# Display info about the dataset.\n",
        "print(ds.schema)\n",
        "\n",
        "# Fetch a xy-slice using the handle.\n",
        "z, t = 36, 0\n",
        "example_xy_slice = ds[:, :, z, t].read().result()\n",
        "\n",
        "# Plot slice.\n",
        "plt.figure(figsize=(6, 12))\n",
        "plt.imshow(example_xy_slice)\n",
        "plt.title(f'xy slice at {z=}, {t=}');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h94FkKvf-hc"
      },
      "source": [
        "## Subsetting the trace matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFImP4ygWhqN"
      },
      "source": [
        "Let's have a look at the trace matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C7GdbAVWLR5"
      },
      "outputs": [],
      "source": [
        "# Create handle to the remote dataset.\n",
        "ds_traces = ts.open({\n",
        "    'open': True,\n",
        "    'driver': 'zarr3',\n",
        "    'kvstore': 'gs://zapbench-release/volumes/20240930/traces'\n",
        "}).result()\n",
        "\n",
        "ds_traces.schema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEfTehhjW5Bg"
      },
      "source": [
        "As described in [the manuscript](https://openreview.net/pdf?id=oCHsDpyawq), the experiment is subdivided into multiple conditions. Using `zapbench.data_utils` we can get the per-condition bounds for indexing the trace matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVgZFVYcd2tZ"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/google-research/zapbench.git#egg=zapbench"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lqmGYUeW38A"
      },
      "outputs": [],
      "source": [
        "from zapbench import constants\n",
        "from zapbench import data_utils\n",
        "\n",
        "# Print the indexing bounds per condition.\n",
        "# Note that we keep a minimal amount of \"padding\" between conditions.\n",
        "for condition_id, condition_name in enumerate(constants.CONDITION_NAMES):\n",
        "  inclusive_min, exclusive_max = data_utils.get_condition_bounds(condition_id)\n",
        "  print(f'{condition_name} has bounds [{inclusive_min}, {exclusive_max}).')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-stosEzHX5yp"
      },
      "source": [
        "Using these bounds, we can get traces for any given condition, e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD9hsGS9X-Od"
      },
      "outputs": [],
      "source": [
        "condition_name = 'turning'\n",
        "\n",
        "# Use the bounds to plot the traces of one of the conditions.\n",
        "inclusive_min, exclusive_max = data_utils.get_condition_bounds(\n",
        "    constants.CONDITION_NAMES.index(condition_name))\n",
        "traces_condition = ds_traces[inclusive_min:exclusive_max, :].read().result()\n",
        "\n",
        "# Plot traces.\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "plt.title(f'traces for {condition_name} condition')\n",
        "im = plt.imshow(traces_condition.T, aspect=\"auto\")\n",
        "plt.xlabel('timestep')\n",
        "plt.ylabel('neuron')\n",
        "cbar = fig.colorbar(im)\n",
        "cbar.set_label(\"normalized activity (df/f)\")\n",
        "plt.show();\n",
        "\n",
        "# For training and testing, we will want to further adjust these bounds for\n",
        "# splits, see `help(data_utils.adjust_condition_bounds_for_split)`.\n",
        "# As this is covered in other notebooks, we will not do this here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WC06GliYYAV"
      },
      "source": [
        "Note that above plotting interpolates heavily, due to the constrained screen-size. Alternatively, we can use [neuroglancer](https://github.com/google/neuroglancer) to visualize datasets, e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBHEHWZddzux"
      },
      "outputs": [],
      "source": [
        "!pip install neuroglancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCTuSpyLYXRd"
      },
      "outputs": [],
      "source": [
        "import neuroglancer as ng\n",
        "\n",
        "dimensions = ng.CoordinateSpace(\n",
        "   names=['time', 'neurons',],\n",
        "   units='',\n",
        "   scales=[1, 1, 1],\n",
        ")\n",
        "viewer = ng.Viewer()\n",
        "with viewer.txn() as s:\n",
        "  s.dimensions = dimensions\n",
        "  s.layers['raw'] = ng.ImageLayer(\n",
        "      source=ng.LocalVolume(traces_condition, dimensions))\n",
        "  s.layout = 'xy'\n",
        "viewer"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
